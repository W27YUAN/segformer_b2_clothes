{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/learn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple, List, Dict, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import evaluate\n",
    "from torch import optim, nn\n",
    "from datasets import load_dataset\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"\n",
    "    Training configuration for the model.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Batch size for training.\n",
    "        epochs: Number of epochs to train for.\n",
    "        learning_rate: Learning rate for the optimizer.\n",
    "        background_weight: Weight for the background class.\n",
    "        other_classes_weight: Weight for the other classes.\n",
    "        lr_decay_rate: Learning rate decay rate.\n",
    "        seed: Random seed for reproducibility.\n",
    "        model_name: Name of the model to use.\n",
    "        project_name: Name of the project for wandb.\n",
    "        device: Device to use for training.\n",
    "    \"\"\"\n",
    "    batch_size: int = 8\n",
    "    epochs: int = 6\n",
    "    learning_rate: float = 1e-4\n",
    "    background_weight: float = 1.0\n",
    "    other_classes_weight: float = 3.0\n",
    "    lr_decay_rate: float = 0.9998\n",
    "    seed: int = 42\n",
    "    model_name: str = \"nvidia/mit-b2\"\n",
    "    project_name: str = \"Clothes segmentation\"\n",
    "    device: Optional[str] = field(\n",
    "        default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return vars(self)\n",
    "\n",
    "\n",
    "config = TrainingConfig(\n",
    "    batch_size=8,\n",
    "    epochs=6,\n",
    "    learning_rate=1e-4,\n",
    "    background_weight=1.0,\n",
    "    other_classes_weight=3.0,\n",
    "    lr_decay_rate=0.9998,\n",
    "    model_name=\"nvidia/mit-b2\",\n",
    "    project_name=\"Clothes segmentation\",\n",
    ")\n",
    "wandb_config = config.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split size: 106\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading and Preparation\n",
    "ds = load_dataset(\"mattmdjaga/human_parsing_dataset\", split=\"train[:100%]\", num_proc=8)\n",
    "ds.shuffle(seed=config.seed)\n",
    "\n",
    "split_ratio: float = 0.006\n",
    "split_size: int = int(len(ds) * split_ratio)\n",
    "print(f\"Split size: {split_size}\")\n",
    "ds_split = ds.train_test_split(test_size=split_ratio, seed=config.seed)\n",
    "train_ds = ds_split[\"train\"]\n",
    "test_ds = ds_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label: Dict[str, str] = {\n",
    "    \"0\": \"Background\",\n",
    "    \"1\": \"Hat\",\n",
    "    \"2\": \"Hair\",\n",
    "    \"3\": \"Sunglasses\",\n",
    "    \"4\": \"Upper-clothes\",\n",
    "    \"5\": \"Skirt\",\n",
    "    \"6\": \"Pants\",\n",
    "    \"7\": \"Dress\",\n",
    "    \"8\": \"Belt\",\n",
    "    \"9\": \"Left-shoe\",\n",
    "    \"10\": \"Right-shoe\",\n",
    "    \"11\": \"Face\",\n",
    "    \"12\": \"Left-leg\",\n",
    "    \"13\": \"Right-leg\",\n",
    "    \"14\": \"Left-arm\",\n",
    "    \"15\": \"Right-arm\",\n",
    "    \"16\": \"Bag\",\n",
    "    \"17\": \"Scarf\",\n",
    "}\n",
    "label2id: Dict[str, str] = {v: k for k, v in id2label.items()}\n",
    "num_labels: int = len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/learn/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b2 and are newly initialized: ['decode_head.classifier.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model and Tokenizer Initialization\n",
    "tokenizer = SegformerImageProcessor.from_pretrained(config.model_name)\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "    config.model_name, num_labels=num_labels, id2label=id2label, label2id=label2id\n",
    ").to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/learn/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Image Transformations\n",
    "img_transforms = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Downscale(p=0.1, scale_min=0.4, scale_max=0.6),\n",
    "                A.GaussNoise(p=0.2),\n",
    "            ],\n",
    "            p=0.1,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(p=0.2),\n",
    "                A.ColorJitter(p=0.2),\n",
    "                A.HueSaturationValue(p=0.2),\n",
    "            ],\n",
    "            p=0.1,\n",
    "        ),\n",
    "        A.OneOf([A.PixelDropout(p=0.2), A.RandomGravel(p=0.2)], p=0.15),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Transformation Functions\n",
    "def train_transforms(example_batch: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Transform the dataset for training.\n",
    "\n",
    "    Args:\n",
    "        example_batch: Batch of examples from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of the inputs to the model.\n",
    "    \"\"\"\n",
    "    trans = [\n",
    "        img_transforms(image=np.array(x), mask=np.array(m))\n",
    "        for x, m in zip(example_batch[\"image\"], example_batch[\"mask\"])\n",
    "    ]\n",
    "    images = [x[\"image\"] for x in trans]\n",
    "    labels = [x[\"mask\"] for x in trans]\n",
    "    inputs = tokenizer(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Transform the dataset for validation.\n",
    "\n",
    "    Args:\n",
    "        example_batch: Batch of examples from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of the inputs to the model.\n",
    "    \"\"\"\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"mask\"]]\n",
    "    inputs = tokenizer(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "train_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and Validation\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics(eval_pred: Tuple[torch.Tensor, torch.Tensor]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute the IOU and accuracy metrics.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: Tuple of logits and labels.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of the metrics.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = logits.argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor\n",
    "\n",
    "    mets = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=num_labels,\n",
    "        ignore_index=255,\n",
    "        reduce_labels=False,\n",
    "    )\n",
    "    for key, value in mets.items():\n",
    "        if type(value) is np.ndarray:\n",
    "            mets[key] = value.tolist()\n",
    "\n",
    "    return mets\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(\n",
    "    model: nn.Module, val_loader: DataLoader\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, List[float]]:\n",
    "    \"\"\"\n",
    "    Perform validation on the model.\n",
    "\n",
    "    Args:\n",
    "        model: Model to validate.\n",
    "        val_loader: Validation data loader.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of logits, labels, and validation losses.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "\n",
    "    for i, batch in enumerate(val_loader, 1):\n",
    "        inputs = batch[\"pixel_values\"].to(config.device)\n",
    "        labels = batch[\"labels\"].to(config.device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            outputs.logits,  # Detach to avoid saving gradients\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "\n",
    "        loss = loss_func(logits_tensor, labels)\n",
    "        val_losses.append(loss.item())\n",
    "\n",
    "        # Storing logits and labels as CPU tensors to save GPU memory\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_logits.append(logits_tensor.cpu())\n",
    "\n",
    "    # Concatenate all logits and labels\n",
    "    logits = torch.cat(all_logits, dim=0).to(config.device)\n",
    "    labels = torch.cat(all_labels, dim=0).to(config.device)\n",
    "\n",
    "    model.train()\n",
    "    return logits, labels, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: nn.Module, tokenizer: SegformerImageProcessor, name: str) -> None:\n",
    "    model.save_pretrained(name)\n",
    "    tokenizer.save_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader, Optimizer, and Scheduler\n",
    "train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_ds, batch_size=config.batch_size, shuffle=False)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lambda1 = lambda step: config.lr_decay_rate**step\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "weights = torch.tensor(\n",
    "    [config.background_weight] + [config.other_classes_weight] * 17\n",
    ").to(config.device)\n",
    "loss_func = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss: List[float] = []\n",
    "\n",
    "# Generating a run name using the configuration parameters\n",
    "run_name: str = \"_\".join([f\"{key}_{value}\" for key, value in wandb_config.items()])\n",
    "t_steps: int = 0  # Used to get metrics at an interval\n",
    "\n",
    "# Initialize wandb with the configuration\n",
    "wandb.init(project=config.project_name, config=wandb_config)\n",
    "wandb.run.name = run_name\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch[\"pixel_values\"].to(config.device)\n",
    "        labels = batch[\"labels\"].to(config.device)\n",
    "        outputs = model(inputs)\n",
    "        # The models predicts small masks, so we need to upsample them to the correct size like in inference\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            outputs.logits,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        loss = loss_func(logits_tensor, labels)\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if t_steps % 600 == 0:\n",
    "            wandb_logs = {}\n",
    "\n",
    "            last_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            logits_tensor, labels, val_losses = validation(model, val_loader)\n",
    "            r_loss = sum(running_loss) / len(running_loss)\n",
    "            val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "            mets = compute_metrics((logits_tensor, labels))\n",
    "\n",
    "            wandb_logs[\"training_loss\"] = r_loss\n",
    "            wandb_logs[\"val_loss\"] = val_loss\n",
    "\n",
    "            for key, value in mets.items():\n",
    "                if isinstance(value, float):\n",
    "                    wandb_logs[key] = value\n",
    "\n",
    "            print(f\"\\nEpoch {epoch} Iteration {i}\")\n",
    "            for key, score in wandb_logs.items():\n",
    "                print(f\"{key}: {score:.3f}\")\n",
    "\n",
    "            print(f\"LR: {last_lr}\")\n",
    "            wandb_logs[\"LR\"] = last_lr\n",
    "            wandb.log(wandb_logs)\n",
    "            running_loss = []\n",
    "        t_steps += 1\n",
    "    save_model(model, tokenizer, f\"{epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
